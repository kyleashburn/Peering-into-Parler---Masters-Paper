{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759028b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# libraries that will let us do LDA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "# library that will let us go ahead and visualize LDA results\n",
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "# helpful library to allow for computing coherence using Gensim\n",
    "import tmtoolkit\n",
    "\n",
    "# what we're using to pickle with\n",
    "import pickle\n",
    "\n",
    "# importing json to serialize the thingy\n",
    "import json\n",
    "\n",
    "# import timing library\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef39c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to override the pre-proc that occurs within the vectorizer\n",
    "# just returns the original string -> because I already had it clean\n",
    "def dummy_func(x):   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b083a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_tokenizer(x):\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b1d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a TFIDF vectorizer with unigram representation\n",
    "# it's cheaper and it will allow for relative pruning (those terms appearing within fewer than .05% of docs or in more than 99%)\n",
    "# feeding in our own functions for splitting and cleaning because otherwise it will mess up our plan\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    min_df =.005, max_df = .99,  preprocessor=dummy_func, tokenizer=cust_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3783de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the model\n",
    "lda_k100 = pickle.load(open(\"min_act_lda_k100.pk\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9c2d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 3s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reading in the data\n",
    "df = pd.read_json(\"min_act_lang_filtered_pre_proc.ndjson\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f38345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 28s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting the vectorizer\n",
    "tf = tfidf_vectorizer.fit_transform(df[\"bo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec1b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a tokenized representation of the cleaned column -> this is needed for the coherence calculation\n",
    "df[\"tokens\"] = df[\"bo\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1001be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashbu\\anaconda3\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 31s\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# computing the coherence of the topic model with K=100\n",
    "k100_coh = tmtoolkit.topicmod.evaluate.metric_coherence_gensim(measure='c_v', \n",
    "                        top_n=25, \n",
    "                        topic_word_distrib=lda_k100.components_, # the components of the lda count as \n",
    "                        dtm=tf, # the term frequency\n",
    "                        vocab=np.array([x for x in tfidf_vectorizer.vocabulary_.keys()]), # pass in vectorizer\n",
    "                        texts=df[\"tokens\"].values) # pass in list of tokenized texts -> needs to match vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3687dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"coh_perp.json\") as f_in:\n",
    "    coh_perp_dict = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919042f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence at K=100: [0.4882727401991226, 0.5332300526438136, 0.5113672902744522, 0.4832750920173118, 0.47971900652122407, 0.4903701882706744, 0.5310071536690575, 0.5701261003589326, 0.5361830886844807, 0.43442710127638334, 0.49738229021626995, 0.4931095460675186, 0.5292690419733748, 0.49937785337725416, 0.47407855918706054, 0.5212633475733971, 0.43826174173472915, 0.515180844903637, 0.4412932638544551, 0.4542853660175258, 0.5287637250690691, 0.4884525749141031, 0.4385969026751829, 0.5391703494041942, 0.5188878802166248, 0.4130327660759948, 0.5443414918171235, 0.4700444792117958, 0.44828466239007003, 0.43256071684015496, 0.43187636930880613, 0.5022712819616462, 0.48097699347536266, 0.5638121793016574, 0.4729011030276271, 0.4896228632148475, 0.5071928353581224, 0.540773730327407, 0.5203643661248433, 0.49507102019252447, 0.4741890122515775, 0.450221542785956, 0.5331021223962427, 0.5093219267092511, 0.5029006387676993, 0.5518212712475032, 0.5055823429678823, 0.5136054444534779, 0.47338273941339953, 0.49883135130130096, 0.5242809302029625, 0.4914838478813467, 0.5417479668195888, 0.5047001053262351, 0.41970745643002194, 0.45350315824915083, 0.5863094763505307, 0.4794834390731455, 0.48623368983043713, 0.45276429280815816, 0.5260208162000639, 0.5163305426102839, 0.5154259091135192, 0.4767958764629818, 0.46714971681635864, 0.4997841833767242, 0.5126035474114544, 0.5242662274408795, 0.4547858034979133, 0.5430976900095286, 0.4741850396295363, 0.5043918727775367, 0.5245423216954123, 0.5009166042516139, 0.40880689642718854, 0.4833647624010843, 0.5419359880059309, 0.49598532505509285, 0.4948943913576208, 0.41375038752951776, 0.521147764991911, 0.5169289785772755, 0.45280473800843823, 0.4866015566429189, 0.4643701939034147, 0.47939316128168274, 0.502668136056779, 0.4366430409140684, 0.4338495257017403, 0.5516104890865432, 0.5042807934926903, 0.45540800579844315, 0.49665599522640846, 0.43421652776122277, 0.5196978477693152, 0.46221361197855054, 0.43310321812678704, 0.4803781786451319, 0.5010954095392606, 0.4619862986358392]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4882727401991226,\n",
       " 0.5332300526438136,\n",
       " 0.5113672902744522,\n",
       " 0.4832750920173118,\n",
       " 0.47971900652122407,\n",
       " 0.4903701882706744,\n",
       " 0.5310071536690575,\n",
       " 0.5701261003589326,\n",
       " 0.5361830886844807,\n",
       " 0.43442710127638334,\n",
       " 0.49738229021626995,\n",
       " 0.4931095460675186,\n",
       " 0.5292690419733748,\n",
       " 0.49937785337725416,\n",
       " 0.47407855918706054,\n",
       " 0.5212633475733971,\n",
       " 0.43826174173472915,\n",
       " 0.515180844903637,\n",
       " 0.4412932638544551,\n",
       " 0.4542853660175258,\n",
       " 0.5287637250690691,\n",
       " 0.4884525749141031,\n",
       " 0.4385969026751829,\n",
       " 0.5391703494041942,\n",
       " 0.5188878802166248,\n",
       " 0.4130327660759948,\n",
       " 0.5443414918171235,\n",
       " 0.4700444792117958,\n",
       " 0.44828466239007003,\n",
       " 0.43256071684015496,\n",
       " 0.43187636930880613,\n",
       " 0.5022712819616462,\n",
       " 0.48097699347536266,\n",
       " 0.5638121793016574,\n",
       " 0.4729011030276271,\n",
       " 0.4896228632148475,\n",
       " 0.5071928353581224,\n",
       " 0.540773730327407,\n",
       " 0.5203643661248433,\n",
       " 0.49507102019252447,\n",
       " 0.4741890122515775,\n",
       " 0.450221542785956,\n",
       " 0.5331021223962427,\n",
       " 0.5093219267092511,\n",
       " 0.5029006387676993,\n",
       " 0.5518212712475032,\n",
       " 0.5055823429678823,\n",
       " 0.5136054444534779,\n",
       " 0.47338273941339953,\n",
       " 0.49883135130130096,\n",
       " 0.5242809302029625,\n",
       " 0.4914838478813467,\n",
       " 0.5417479668195888,\n",
       " 0.5047001053262351,\n",
       " 0.41970745643002194,\n",
       " 0.45350315824915083,\n",
       " 0.5863094763505307,\n",
       " 0.4794834390731455,\n",
       " 0.48623368983043713,\n",
       " 0.45276429280815816,\n",
       " 0.5260208162000639,\n",
       " 0.5163305426102839,\n",
       " 0.5154259091135192,\n",
       " 0.4767958764629818,\n",
       " 0.46714971681635864,\n",
       " 0.4997841833767242,\n",
       " 0.5126035474114544,\n",
       " 0.5242662274408795,\n",
       " 0.4547858034979133,\n",
       " 0.5430976900095286,\n",
       " 0.4741850396295363,\n",
       " 0.5043918727775367,\n",
       " 0.5245423216954123,\n",
       " 0.5009166042516139,\n",
       " 0.40880689642718854,\n",
       " 0.4833647624010843,\n",
       " 0.5419359880059309,\n",
       " 0.49598532505509285,\n",
       " 0.4948943913576208,\n",
       " 0.41375038752951776,\n",
       " 0.521147764991911,\n",
       " 0.5169289785772755,\n",
       " 0.45280473800843823,\n",
       " 0.4866015566429189,\n",
       " 0.4643701939034147,\n",
       " 0.47939316128168274,\n",
       " 0.502668136056779,\n",
       " 0.4366430409140684,\n",
       " 0.4338495257017403,\n",
       " 0.5516104890865432,\n",
       " 0.5042807934926903,\n",
       " 0.45540800579844315,\n",
       " 0.49665599522640846,\n",
       " 0.43421652776122277,\n",
       " 0.5196978477693152,\n",
       " 0.46221361197855054,\n",
       " 0.43310321812678704,\n",
       " 0.4803781786451319,\n",
       " 0.5010954095392606,\n",
       " 0.4619862986358392]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the coherence to the json file\n",
    "# printing coherence and adding it to the dict\n",
    "print(\"Coherence at K=100:\", k100_coh)\n",
    "coh_perp_dict[\"k100\"].setdefault(\"coherence\", k100_coh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eea74166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'perplexity': 3382.639084473857,\n",
       " 'coherence': [0.4882727401991226,\n",
       "  0.5332300526438136,\n",
       "  0.5113672902744522,\n",
       "  0.4832750920173118,\n",
       "  0.47971900652122407,\n",
       "  0.4903701882706744,\n",
       "  0.5310071536690575,\n",
       "  0.5701261003589326,\n",
       "  0.5361830886844807,\n",
       "  0.43442710127638334,\n",
       "  0.49738229021626995,\n",
       "  0.4931095460675186,\n",
       "  0.5292690419733748,\n",
       "  0.49937785337725416,\n",
       "  0.47407855918706054,\n",
       "  0.5212633475733971,\n",
       "  0.43826174173472915,\n",
       "  0.515180844903637,\n",
       "  0.4412932638544551,\n",
       "  0.4542853660175258,\n",
       "  0.5287637250690691,\n",
       "  0.4884525749141031,\n",
       "  0.4385969026751829,\n",
       "  0.5391703494041942,\n",
       "  0.5188878802166248,\n",
       "  0.4130327660759948,\n",
       "  0.5443414918171235,\n",
       "  0.4700444792117958,\n",
       "  0.44828466239007003,\n",
       "  0.43256071684015496,\n",
       "  0.43187636930880613,\n",
       "  0.5022712819616462,\n",
       "  0.48097699347536266,\n",
       "  0.5638121793016574,\n",
       "  0.4729011030276271,\n",
       "  0.4896228632148475,\n",
       "  0.5071928353581224,\n",
       "  0.540773730327407,\n",
       "  0.5203643661248433,\n",
       "  0.49507102019252447,\n",
       "  0.4741890122515775,\n",
       "  0.450221542785956,\n",
       "  0.5331021223962427,\n",
       "  0.5093219267092511,\n",
       "  0.5029006387676993,\n",
       "  0.5518212712475032,\n",
       "  0.5055823429678823,\n",
       "  0.5136054444534779,\n",
       "  0.47338273941339953,\n",
       "  0.49883135130130096,\n",
       "  0.5242809302029625,\n",
       "  0.4914838478813467,\n",
       "  0.5417479668195888,\n",
       "  0.5047001053262351,\n",
       "  0.41970745643002194,\n",
       "  0.45350315824915083,\n",
       "  0.5863094763505307,\n",
       "  0.4794834390731455,\n",
       "  0.48623368983043713,\n",
       "  0.45276429280815816,\n",
       "  0.5260208162000639,\n",
       "  0.5163305426102839,\n",
       "  0.5154259091135192,\n",
       "  0.4767958764629818,\n",
       "  0.46714971681635864,\n",
       "  0.4997841833767242,\n",
       "  0.5126035474114544,\n",
       "  0.5242662274408795,\n",
       "  0.4547858034979133,\n",
       "  0.5430976900095286,\n",
       "  0.4741850396295363,\n",
       "  0.5043918727775367,\n",
       "  0.5245423216954123,\n",
       "  0.5009166042516139,\n",
       "  0.40880689642718854,\n",
       "  0.4833647624010843,\n",
       "  0.5419359880059309,\n",
       "  0.49598532505509285,\n",
       "  0.4948943913576208,\n",
       "  0.41375038752951776,\n",
       "  0.521147764991911,\n",
       "  0.5169289785772755,\n",
       "  0.45280473800843823,\n",
       "  0.4866015566429189,\n",
       "  0.4643701939034147,\n",
       "  0.47939316128168274,\n",
       "  0.502668136056779,\n",
       "  0.4366430409140684,\n",
       "  0.4338495257017403,\n",
       "  0.5516104890865432,\n",
       "  0.5042807934926903,\n",
       "  0.45540800579844315,\n",
       "  0.49665599522640846,\n",
       "  0.43421652776122277,\n",
       "  0.5196978477693152,\n",
       "  0.46221361197855054,\n",
       "  0.43310321812678704,\n",
       "  0.4803781786451319,\n",
       "  0.5010954095392606,\n",
       "  0.4619862986358392]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coh_perp_dict[\"k100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "035d47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serializing the dict\n",
    "# saving the the test run coherence and perplexity for each of the models\n",
    "with open('coh_perp.json', 'w') as outfile:\n",
    "    json.dump(coh_perp_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77ad557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashbu\\anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5h 42min 21s\n",
      "Wall time: 8h 38min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# creating the viz & saving the viz\n",
    "\n",
    "# making the visualization, showing it, and saving it\n",
    "vis = pyLDAvis.sklearn.prepare(lda_k100, tf, tfidf_vectorizer) # lda_tf, dtm, tf_vectorizzer\n",
    "vis\n",
    "pyLDAvis.save_html(vis,\"ldak100_pyldavis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a645fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
