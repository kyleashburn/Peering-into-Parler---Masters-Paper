{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199d4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the neccessary libraries for this work\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdc81308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the files we'll be putting the data into\n",
    "min_act = open(\"min_act.ndjson\",\"a\", encoding='utf-8')\n",
    "mod_act = open(\"mod_act.ndjson\",\"a\", encoding='utf-8')\n",
    "ver_act = open(\"ver_act.ndjson\",\"a\", encoding='utf-8')\n",
    "ext_act = open(\"ext_act.ndjson\",\"a\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cdc7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 39s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# opening the ndjson file to make a dictionary of username classes\n",
    "uname_dict = {}\n",
    "count_urls = 0\n",
    "\n",
    "# getting username activities\n",
    "with open(\"post.ndjson\", encoding=\"utf-8\") as f_in:\n",
    "    for line in f_in:\n",
    "        line_json = json.loads(line)\n",
    "        \n",
    "        # checking the username is in the json; if not it's not useful for us\n",
    "        if \"un\" in line_json:\n",
    "            # checking if the line has a body OR a url\n",
    "            # this matters b/c of the way the data is structured\n",
    "            # sometimes we don't have any body because the body consisted solely of a URL which was removed as part of pre-proc\n",
    "            if \"bo\" or \"url\" in line_json:\n",
    "                uname = line_json[\"un\"]\n",
    "                \n",
    "                if uname not in uname_dict:\n",
    "                    uname_dict.setdefault(uname, 1)\n",
    "\n",
    "                else:\n",
    "                    uname_dict[uname] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cab07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 812 ms\n",
      "Wall time: 819 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bucket_count = {\"min_act\":0, \"mod_act\":0, \"ver_act\":0, \"ext_act\":0}\n",
    "\n",
    "for uname in uname_dict:\n",
    "    # getting the count for the numbers of users in each bucket\n",
    "            if uname_dict[uname] < 100:\n",
    "                bucket_count[\"min_act\"] += 1\n",
    "                \n",
    "            elif uname_dict[uname] >= 100 and uname_dict[uname] < 1000:\n",
    "                bucket_count[\"mod_act\"] += 1\n",
    "                                     \n",
    "            elif uname_dict[uname] >= 1000 and uname_dict[uname] < 10000:\n",
    "                bucket_count[\"ver_act\"] += 1\n",
    "                \n",
    "            elif uname_dict[uname] > 10000:\n",
    "                bucket_count[\"ext_act\"] += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe8d780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_act': 2346024, 'mod_act': 21247, 'ver_act': 2325, 'ext_act': 97}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "279ab660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining function to choose the things we care about\n",
    "def line_clean(line_json):\n",
    "    \n",
    "    line_data = {}\n",
    "\n",
    "    if \"t\" in line_json: # t = type of item\n",
    "        line_data.setdefault(\"t\",line_json[\"t\"])\n",
    "    \n",
    "    if \"id\" in line_json: # id = uid for item\n",
    "        line_data.setdefault(\"id\",line_json[\"id\"])\n",
    "\n",
    "    if \"cd\" in line_json: # cd = creation date -> yyyymmdd\n",
    "        line_data.setdefault(\"cd\",line_json[\"cd\"])\n",
    "\n",
    "    if \"c\" in line_json: # c = creation date -> unix epoch\n",
    "        line_data.setdefault(\"c\",line_json[\"c\"])\n",
    "\n",
    "    if \"u\" in line_json: # u = uid for user\n",
    "        line_data.setdefault(\"u\",line_json[\"u\"])\n",
    "\n",
    "    if \"un\" in line_json: # un = username for user\n",
    "        line_data.setdefault(\"un\",line_json[\"un\"])\n",
    "    \n",
    "    if \"dmn\" in line_json: # dmn = list of domains\n",
    "        line_data.setdefault(\"dmn\",line_json[\"dmn\"])\n",
    "    \n",
    "    if \"bo\" in line_json: # bo = body of text\n",
    "        line_data.setdefault(\"bo\",line_json[\"bo\"])\n",
    "    \n",
    "    return line_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004d41c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 25s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# splitting the posts up\n",
    "posts_written = {\"min_act\":0, \"mod_act\":0, \"ver_act\":0, \"ext_act\":0}\n",
    "\n",
    "# opening the ndjson file\n",
    "with open(\"post.ndjson\", encoding=\"utf-8\") as f_in:\n",
    "    for line in f_in:\n",
    "        line_json = json.loads(line)\n",
    "        \n",
    "        \n",
    "        # filtering out lines lacking a uname; if there's no uname we can't really work with it\n",
    "        if \"un\" in line_json:\n",
    "            uname = line_json[\"un\"]          \n",
    "            \n",
    "            # pulling the elements we care about from the line_json\n",
    "            line_json = line_clean(line_json)\n",
    "                        \n",
    "            # filtering lines into appropriate files\n",
    "            if uname_dict[uname] < 100:\n",
    "                \n",
    "                \n",
    "                        posts_written[\"min_act\"] += 1\n",
    "                        \n",
    "                        # using json.dumps to create json object & adding a newline to make ndjson\n",
    "                        min_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                \n",
    "            elif uname_dict[uname] >= 100 and uname_dict[uname] < 1000:\n",
    "                \n",
    "                        mod_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                        posts_written[\"mod_act\"] += 1\n",
    "\n",
    "            \n",
    "            elif uname_dict[uname] >= 1000 and uname_dict[uname] < 10000:\n",
    "                \n",
    "                        ver_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                        posts_written[\"ver_act\"] += 1\n",
    "\n",
    "                \n",
    "            elif uname_dict[uname] > 10000:\n",
    "                    \n",
    "                        ext_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                        posts_written[\"ext_act\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d9aa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_act': 7272338, 'mod_act': 5647816, 'ver_act': 5689503, 'ext_act': 1984388}\n"
     ]
    }
   ],
   "source": [
    "print(posts_written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ecc8f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16min 45s\n",
      "Wall time: 16min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# checking the comments\n",
    "\n",
    "comments_written = {\"min_act\":0, \"mod_act\":0, \"ver_act\":0, \"ext_act\":0}\n",
    "\n",
    "no_post_count = 0\n",
    "\n",
    "with open(\"comment.ndjson\", encoding=\"utf-8\") as f_in:\n",
    "    for line in f_in:\n",
    "        line_json = json.loads(line)\n",
    "        \n",
    "        # pulling the elements we care about from the line_json\n",
    "        line_json = line_clean(line_json)\n",
    "            \n",
    "        # filtering out lines lacking a uname; if there's no uname we can't really work with it\n",
    "        if \"un\" in line_json:\n",
    "            uname = line_json[\"un\"]          \n",
    "            \n",
    "            # ensuring that the uname is actually tracked by us (meaning they posted either text or a url)\n",
    "            if uname in uname_dict:\n",
    "                \n",
    "                # filtering lines into appropriate files\n",
    "                if uname_dict[uname] < 100:\n",
    "\n",
    "                            comments_written[\"min_act\"] += 1\n",
    "                            \n",
    "                            # using json.dumps to create json object & adding a newline to make ndjson\n",
    "                            min_act.write(json.dumps(line_json)+\"\\n\")\n",
    "\n",
    "                elif uname_dict[uname] >= 100 and uname_dict[uname] < 1000:\n",
    "\n",
    "                            mod_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                            comments_written[\"mod_act\"] += 1\n",
    "\n",
    "\n",
    "                elif uname_dict[uname] >= 1000 and uname_dict[uname] < 10000:\n",
    "\n",
    "                            ver_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                            comments_written[\"ver_act\"] += 1\n",
    "\n",
    "\n",
    "                elif uname_dict[uname] > 10000:\n",
    "\n",
    "                            ext_act.write(json.dumps(line_json)+\"\\n\")\n",
    "                            comments_written[\"ext_act\"] += 1\n",
    "                        \n",
    "            # else they didn't have any posts so we can't really work with their comment under our system\n",
    "            else:\n",
    "                no_post_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3d86315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_act': 18033602, 'mod_act': 12062604, 'ver_act': 5516705, 'ext_act': 270038}\n"
     ]
    }
   ],
   "source": [
    "print(comments_written)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "499da60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_act.close()\n",
    "mod_act.close()\n",
    "ver_act.close()\n",
    "ext_act.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33194576",
   "metadata": {},
   "source": [
    "From the start, we can see that the levels of activity using posts as a metric for engagment don't bear out when applied to comments. Instead, what we see is that the minimally active users have the most comments out of any group. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
